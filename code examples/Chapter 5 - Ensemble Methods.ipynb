{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5 - Ensmble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from utils import *\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bias-Variance Trade-off\n",
    "\n",
    "$\\newcommand{\\coloneqq}{\\mathrel{\\vcenter{:}}=}$\n",
    "$\\newcommand{\\E}{\\mathbb{E}}$\n",
    "$\\newcommand{\\y}{\\mathbf{y}}$\n",
    "\n",
    "Let us compute the bias-variance trade-off graph for a problem of polynomial fitting. Recall, that the error decomposition for the MSE loss function is: $$ MSE_{\\y}\\left(\\widehat{\\y}\\right)=\\E\\left[\\left(\\widehat{\\y}-\\y^*\\right)^2\\right] = Var\\left(\\widehat{\\y}\\right) + Bias^2\\left(\\widehat{\\y}\\right) $$\n",
    "\n",
    "Where the bias and variances of estimators are defined as: $$ Bias\\left(\\widehat{\\y}\\right) \\coloneqq \\E\\left[\\widehat{\\y}\\right] - \\y, \\quad Var\\left(\\widehat{\\y}\\right)\\coloneqq \\E\\left[\\left(\\widehat{\\y}-\\E\\left[\\widehat{\\y}\\right]\\right)^2\\right]$$\n",
    "\n",
    "As the $\\E\\left[\\widehat{\\y}\\right]$ is over the selection of the training sets, we will first defined the \"ground truth\" model and retrieve a set $\\mathbf{X},\\y$ from it. Then, we will repeatedly sample Gaussian noise $\\varepsilon$ and fit a polynomial model over $\\mathbf{X},\\y+\\varepsilon$. In the code below `y_` denotes the true $\\y$ values and `y` the responses after adding the noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../figures/bias_variance_poly.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-28333bc5f50e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     49\u001b[0m                          \u001b[0mxaxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34mr\"$\\text{Degree of Fitted Polymonial}$\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                          width=800, height=500))\n\u001b[1;32m---> 51\u001b[1;33m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"../figures/bias_variance_poly.png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\iml.env\\lib\\site-packages\\plotly\\basedatatypes.py\u001b[0m in \u001b[0;36mwrite_image\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3804\u001b[0m         \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3805\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3806\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3807\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3808\u001b[0m     \u001b[1;31m# Static helpers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\iml.env\\lib\\site-packages\\plotly\\io\\_kaleido.py\u001b[0m in \u001b[0;36mwrite_image\u001b[1;34m(fig, file, format, scale, width, height, validate, engine)\u001b[0m\n\u001b[0;32m    256\u001b[0m     \u001b[1;31m# ---------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfile_is_str\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"wb\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    259\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../figures/bias_variance_poly.png'"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate data according to a polynomial model of degree 4\n",
    "model = lambda x: x**4 - 2*x**3 - .5*x**2 + 1\n",
    "X = np.linspace(-1.6, 2, 60)\n",
    "y = model(X).astype(np.float64)\n",
    "X_train, X_test, y_train_, y_test_ = train_test_split(X, y, test_size=.5, random_state=13)\n",
    "\n",
    "\n",
    "# The following functions recieve two matrices of the true values and the predictions\n",
    "# where rows represent different runs and columns the different responses in the run\n",
    "def variance(y_pred):\n",
    "    return np.mean(np.var(y_pred - np.mean(y_pred, axis=0), axis=0, ddof=1))\n",
    "\n",
    "def bias(y_pred, y_true):\n",
    "    mean_y = y_pred.mean(axis=0)\n",
    "    return np.mean((mean_y - y_true)**2)\n",
    "\n",
    "def error(y_pred, y):\n",
    "    return np.mean((y_pred - y)**2)\n",
    "\n",
    "\n",
    "\n",
    "ks, repetitions = list(range(11)), 100\n",
    "biases, variances, errors = np.zeros(len(ks)), np.zeros(len(ks)), np.zeros(len(ks))\n",
    "for i, k in enumerate(ks):\n",
    "    # Add noise to train and test samples\n",
    "    y_train = y_train_[np.newaxis, :] + np.random.normal(0, 3, size=(repetitions, len(y_train_)))\n",
    "    y_test  = y_test_ + np.random.normal(size=len(y_test_))\n",
    "    \n",
    "    # Fit model multiple times (each time over a slightly different training sample) and predict over test set\n",
    "    y_preds = np.array([make_pipeline(PolynomialFeatures(k), LinearRegression())\\\n",
    "                            .fit(X_train.reshape(-1,1), y_train[j,:])\\\n",
    "                            .predict(X_test.reshape(-1,1))\n",
    "                        for j in range(repetitions)])\n",
    "    \n",
    "    biases[i], variances[i], errors[i] = bias(y_preds, y_test_), variance(y_preds), error(y_preds, y_test_)\n",
    "\n",
    "\n",
    "fig = go.Figure([\n",
    "            go.Scatter(x=ks, y=biases, name=r\"$Bias^2$\"),\n",
    "            go.Scatter(x=ks, y=variances, name=r\"$Variance$\"),\n",
    "            go.Scatter(x=ks, y=biases+variances, name=r\"$Bias^2+Variance$\"),\n",
    "            go.Scatter(x=ks, y=errors, name=r\"$Generalization\\,\\,Error$\")], \n",
    "        layout=go.Layout(title=r\"$\\text{Generalization Error Decomposition - Bias-Variance of Polynomial Fitting}$\",\n",
    "                         xaxis=dict(title=r\"$\\text{Degree of Fitted Polymonial}$\"),\n",
    "                         width=800, height=500))\n",
    "fig.write_image(f\"../figures/bias_variance_poly.png\")\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Committee Decisions\n",
    "\n",
    "Let $X_1,\\ldots,X_T\\overset{iid}{\\sim}Ber\\left(p\\right)$ taking values in $\\left\\{\\pm1\\right\\}$, with the probability of each being correct being $p>0.5$. We can bound the probability of the committee being correct by: $$\\mathbb{P}\\left(\\sum X_i > 0\\right) \\geq 1-\\exp\\left(-\\frac{T}{2p}\\left(p-\\frac{1}{2}\\right)^2\\right)$$\n",
    "\n",
    "Let us show this bounding below empirically by sampling increasing amount of such Bernoulli random variables, and to do so for different values of $p$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bound = np.vectorize(lambda p, T: 1-np.exp(-(T/(2*p))*(p-.5)**2))\n",
    "\n",
    "ps  = np.concatenate([[.5001], np.linspace(.55, 1, 14)])\n",
    "Ts = [1,5,10,15,20,25,50,75,100,125,150,175,200,250,300,400,500,600]\n",
    "\n",
    "frames = []\n",
    "for p in ps:\n",
    "    theoretical = bound(p,Ts)\n",
    "    empirical = np.array([[np.sum(np.random.choice([1, -1], T, p=[p, 1-p])) > 0 for _ in range(100)] for T in Ts])\n",
    "    \n",
    "    frames.append(go.Frame(data=[go.Scatter(x=Ts, y=theoretical, mode=\"markers+lines\", name=\"Theoretical Bound\",\n",
    "                                            line=dict(color=\"grey\", dash='dash')),\n",
    "                                 go.Scatter(x=Ts, y=empirical.mean(axis=1), \n",
    "                                            error_y = dict(type=\"data\", array=empirical.var(axis=1)),\n",
    "                                            mode=\"markers+lines\", marker_color=\"black\", name=\"Empirical Probability\")],\n",
    "                           layout=go.Layout(\n",
    "                               title_text=r\"$\\text{{Committee Correctness Probability As Function of }}\\\n",
    "                               T\\text{{: }}p={0}$\".format(round(p,3)),\n",
    "                               xaxis=dict(title=r\"$T \\text{ - Committee Size}$\"),\n",
    "                               yaxis=dict(title=r\"$\\text{Probability of Being Correct}$\", range=[0.0001,1.01]))))\n",
    "\n",
    "\n",
    "fig = go.Figure(data=frames[0][\"data\"],\n",
    "        frames=frames[1:], \n",
    "        layout=go.Layout(\n",
    "            title=frames[0][\"layout\"][\"title\"],\n",
    "            xaxis=frames[0][\"layout\"][\"xaxis\"],\n",
    "            yaxis=frames[0][\"layout\"][\"yaxis\"],\n",
    "            updatemenus=[dict(type=\"buttons\", buttons=[AnimationButtons.play(frame_duration=1000), \n",
    "                                                       AnimationButtons.pause()])] ))\n",
    "\n",
    "animation_to_gif(fig, \"../figures/committee_decision_correctness.gif\", 700, width=600, height=450)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, of uncorrelated committee members, we have shown the variance in the committee decision is: $$ Var\\left(\\sum X_i\\right) = \\frac{4}{T}p\\left(1-p\\right)$$\n",
    "Let us simulate such a scenario and see what is the empirical variance we achieve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps  = np.concatenate([[.5001], np.linspace(.55, 1, 10)])\n",
    "Ts = [1,5,10,15,20,25,50,75,100,125,150,175,200,250,300,400,500,600]\n",
    "\n",
    "    results = np.array([np.var(np.random.binomial(Ts, p, (10000, len(Ts))) >= (np.array(Ts)/2), axis=0, ddof=1) for p in ps])\n",
    "\n",
    "df = pd.DataFrame(results, columns=Ts, index=ps)\n",
    "fig = go.Figure(go.Heatmap(x=df.columns.tolist(), y=df.index.tolist(), z=df.values.tolist(), colorscale=\"amp\"),\n",
    "          layout=go.Layout(title=r\"$\\text{Variance of Committee Decision - Independent Members}$\", \n",
    "                           xaxis=dict(title=r\"$T\\text{ - Committee Size}$\", type=\"category\"),\n",
    "                           yaxis=dict(title=r\"$p\\text{ - Member Correctness Probability}$\"),\n",
    "                           width=800, height=500))\n",
    "\n",
    "fig.write_image(\"../figures/uncorrelated_committee_decision.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a set of correlated random variables, with correlation coefficient of $\\rho$ and variance of $\\sigma^2$, the variane of the committee's decision is: $$ Var\\left(\\sum X_i\\right) = \\rho \\sigma^2 + \\frac{1}{T}\\left(1-\\rho\\right)\\sigma^2 $$\n",
    "Let us set $\\sigma^2$ and investigate the relation between $\\rho$ and $T$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sigma = round((lambda p: p*(1-p))(.6), 3)\n",
    "repeats = 10000\n",
    "rho = np.linspace(0,1, 10)\n",
    "Ts = np.array([1,5,10,15,20,25,50,75,100,125,150,175,200,250,300,400,500,600])\n",
    "\n",
    "variances = np.zeros((len(rho), len(Ts)))\n",
    "for i, r in enumerate(rho):\n",
    "    # Perform `repetitions` times T Bernoulli experiments\n",
    "    decisions = np.random.binomial(1, sigma, size=(repeats, max(Ts)))\n",
    "    change = np.c_[np.zeros(decisions.shape[0]), np.random.uniform(size=(repeats, max(Ts)-1)) <= r]\n",
    "    correlated_decisions = np.ma.array(decisions, mask=change).filled(fill_value=decisions[:,0][:, None])\n",
    "    correlated_decisions[correlated_decisions == 0] = -1\n",
    "\n",
    "    variances[i,:] = np.var(np.cumsum(correlated_decisions, axis=1) >= 0, axis=0)[Ts-1]\n",
    "    \n",
    "df = pd.DataFrame(variances, columns=Ts, index=rho)\n",
    "fig = go.Figure(go.Heatmap(x=df.columns.tolist(), y=df.index.tolist(), z=df.values.tolist(), colorscale=\"amp\"),\n",
    "          layout=go.Layout(title=rf\"$\\text{{Variance of Committee Decision - Correlated Committee Members - Member Decision Variance }}\\sigma^2 = {sigma}$\", \n",
    "                           xaxis=dict(title=r\"$T\\text{ - Committee Size}$\", type=\"category\"),\n",
    "                           yaxis=dict(title=r\"$\\rho\\text{ - Correlation Between Members}$\"),\n",
    "                           width=500, height=300))\n",
    "\n",
    "fig.write_image(\"../figures/correlated_committee_decision.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "### Empirical CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "from scipy.stats import norm\n",
    "\n",
    "data = np.random.normal(size=10000)\n",
    "frames = []\n",
    "for m in [5,10, 15, 20, 25, 50, 75, 100, 150, 200, 250, 500, 750, 1000,1500, 2000, 2500, 5000, 7500, 10000]:\n",
    "    ecdf = ECDF(data[:m])\n",
    "    frames.append(go.Frame(\n",
    "        data = [\n",
    "            go.Scatter(x=data[:m], y=[-.1]*m, mode=\"markers\", marker=dict(size=5, color=norm.pdf(data[:m])), name=\"Samples\"),\n",
    "            go.Scatter(x=ecdf.x, y=ecdf.y, marker_color=\"black\", name=\"Empirical CDF\"),                \n",
    "            go.Scatter(x=np.linspace(-3,3,100), y=norm.cdf(np.linspace(-3,3,100), 0, 1), mode=\"lines\", \n",
    "                       line=dict(color=\"grey\", dash='dash'), name=\"Theoretical CDF\")],\n",
    "        layout = go.Layout(title=rf\"$\\text{{Empirical CDF of }}m={m}\\text{{ Samples Drawn From }}\\mathcal{{N}}\\left(0,1\\right)$\")\n",
    "    ))\n",
    "\n",
    "fig = go.Figure(data = frames[0].data, frames=frames[1:], \n",
    "                layout=go.Layout(title=frames[0].layout.title,\n",
    "                                 updatemenus=[dict(type=\"buttons\", buttons=[AnimationButtons.play(frame_duration=1000), \n",
    "                                                                            AnimationButtons.pause()])]))\n",
    "\n",
    "\n",
    "animation_to_gif(fig, \"../figures/empirical_cdf.gif\", 700, width=600, height=450)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collection of Bagged Decision Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.utils import resample\n",
    "np.random.seed(7)\n",
    "\n",
    "class TreeEnsemble:\n",
    "    def __init__(self, num_of_trees, d):\n",
    "        self.trees = []\n",
    "        self.num_of_trees = num_of_trees\n",
    "        self.depth = d\n",
    "        \n",
    "    def fit_bootstrap_tree(self, X, y):\n",
    "        idx = resample(range(len(X)), replace = True, n_samples = len(X))\n",
    "        return DecisionTreeClassifier(max_depth=self.depth).fit(X[idx], y[idx])\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.trees = [self.fit_bootstrap_tree(X, y) for _ in range(self.num_of_trees)]\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.partial_predict(X)\n",
    "    \n",
    "    def partial_predict(self, X):\n",
    "        samples_proba = self.predict_proba(X)  # samples_proba[0]: probablity for class \"0\". samples_proba[1]: probablity for class \"1\".\n",
    "        return np.argmax(samples_proba, axis=1)  # returns for each sample, the index of the maximum probability class\n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        # This function calculates the probability of each class (\"0\"/\"1\") for each sample.\n",
    "        trees_mean = np.mean([self.trees[t].predict(X) for t in range(self.num_of_trees)], axis=0)\n",
    "        return np.stack((1-trees_mean, trees_mean), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "$\\text{Ensemble}$",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350
         ],
         "y": [
          0.348,
          0.342,
          0.342,
          0.33,
          0.356,
          0.34,
          0.34,
          0.336,
          0.304,
          0.348,
          0.338,
          0.342,
          0.336,
          0.346,
          0.332,
          0.288,
          0.346,
          0.304,
          0.338,
          0.35,
          0.304,
          0.3,
          0.302,
          0.344,
          0.298,
          0.328,
          0.346,
          0.296,
          0.344,
          0.33,
          0.342,
          0.342,
          0.354,
          0.32,
          0.306,
          0.304,
          0.298,
          0.296,
          0.304,
          0.302,
          0.332,
          0.298,
          0.304,
          0.3,
          0.308,
          0.296,
          0.298,
          0.302,
          0.304,
          0.356,
          0.298,
          0.304,
          0.302,
          0.308,
          0.29,
          0.306,
          0.302,
          0.308,
          0.296,
          0.296,
          0.3,
          0.298,
          0.284,
          0.302,
          0.302,
          0.338,
          0.308,
          0.298,
          0.3,
          0.3,
          0.318,
          0.302,
          0.302,
          0.306,
          0.3,
          0.3,
          0.302,
          0.302,
          0.302,
          0.306,
          0.302,
          0.3,
          0.306,
          0.3,
          0.306,
          0.302,
          0.304,
          0.344,
          0.302,
          0.344,
          0.298,
          0.3,
          0.288,
          0.308,
          0.338,
          0.306,
          0.338,
          0.302,
          0.298,
          0.3,
          0.302,
          0.304,
          0.296,
          0.306,
          0.298,
          0.298,
          0.304,
          0.34,
          0.298,
          0.302,
          0.294,
          0.304,
          0.296,
          0.298,
          0.322,
          0.298,
          0.3,
          0.338,
          0.302,
          0.34,
          0.304,
          0.308,
          0.3,
          0.298,
          0.3,
          0.306,
          0.288,
          0.298,
          0.34,
          0.338,
          0.304,
          0.3,
          0.304,
          0.298,
          0.306,
          0.338,
          0.304,
          0.334,
          0.302,
          0.3,
          0.296,
          0.304,
          0.302,
          0.302,
          0.3,
          0.302,
          0.306,
          0.3,
          0.304,
          0.3,
          0.294,
          0.304,
          0.3,
          0.3,
          0.3,
          0.302,
          0.306,
          0.304,
          0.29,
          0.338,
          0.302,
          0.3,
          0.302,
          0.342,
          0.302,
          0.27,
          0.298,
          0.3,
          0.306,
          0.3,
          0.298,
          0.302,
          0.298,
          0.3,
          0.298,
          0.3,
          0.298,
          0.3,
          0.306,
          0.3,
          0.302,
          0.306,
          0.302,
          0.3,
          0.302,
          0.302,
          0.304,
          0.3,
          0.298,
          0.302,
          0.302,
          0.304,
          0.302,
          0.298,
          0.296,
          0.296,
          0.302,
          0.3,
          0.306,
          0.306,
          0.3,
          0.3,
          0.294,
          0.294,
          0.34,
          0.286,
          0.284,
          0.296,
          0.3,
          0.302,
          0.3,
          0.306,
          0.3,
          0.302,
          0.304,
          0.304,
          0.304,
          0.298,
          0.302,
          0.302,
          0.306,
          0.304,
          0.302,
          0.3,
          0.302,
          0.304,
          0.3,
          0.302,
          0.3,
          0.306,
          0.304,
          0.298,
          0.298,
          0.292,
          0.3,
          0.3,
          0.3,
          0.302,
          0.302,
          0.3,
          0.3,
          0.302,
          0.302,
          0.306,
          0.298,
          0.298,
          0.304,
          0.3,
          0.3,
          0.296,
          0.306,
          0.306,
          0.304,
          0.3,
          0.306,
          0.302,
          0.3,
          0.3,
          0.302,
          0.306,
          0.3,
          0.3,
          0.306,
          0.306,
          0.298,
          0.3,
          0.296,
          0.302,
          0.298,
          0.302,
          0.306,
          0.298,
          0.298,
          0.304,
          0.306,
          0.292,
          0.302,
          0.306,
          0.304,
          0.298,
          0.306,
          0.298,
          0.298,
          0.302,
          0.3,
          0.302,
          0.304,
          0.298,
          0.304,
          0.306,
          0.296,
          0.3,
          0.296,
          0.3,
          0.302,
          0.304,
          0.286,
          0.302,
          0.306,
          0.302,
          0.302,
          0.302,
          0.3,
          0.302,
          0.304,
          0.302,
          0.302,
          0.3,
          0.3,
          0.306,
          0.302,
          0.304,
          0.302,
          0.298,
          0.304,
          0.306,
          0.302,
          0.306,
          0.306,
          0.304,
          0.3,
          0.302,
          0.306,
          0.3,
          0.302,
          0.304,
          0.3,
          0.302,
          0.304,
          0.306,
          0.304,
          0.296,
          0.304,
          0.306,
          0.304,
          0.296,
          0.306,
          0.302,
          0.306,
          0.298,
          0.302,
          0.3,
          0.3,
          0.302,
          0.298,
          0.306,
          0.304,
          0.3,
          0.304,
          0.298
         ]
        },
        {
         "mode": "lines",
         "name": "$\\text{Single Tree}$",
         "type": "scatter",
         "x": [
          1,
          2,
          3,
          4,
          5,
          6,
          7,
          8,
          9,
          10,
          11,
          12,
          13,
          14,
          15,
          16,
          17,
          18,
          19,
          20,
          21,
          22,
          23,
          24,
          25,
          26,
          27,
          28,
          29,
          30,
          31,
          32,
          33,
          34,
          35,
          36,
          37,
          38,
          39,
          40,
          41,
          42,
          43,
          44,
          45,
          46,
          47,
          48,
          49,
          50,
          51,
          52,
          53,
          54,
          55,
          56,
          57,
          58,
          59,
          60,
          61,
          62,
          63,
          64,
          65,
          66,
          67,
          68,
          69,
          70,
          71,
          72,
          73,
          74,
          75,
          76,
          77,
          78,
          79,
          80,
          81,
          82,
          83,
          84,
          85,
          86,
          87,
          88,
          89,
          90,
          91,
          92,
          93,
          94,
          95,
          96,
          97,
          98,
          99,
          100,
          101,
          102,
          103,
          104,
          105,
          106,
          107,
          108,
          109,
          110,
          111,
          112,
          113,
          114,
          115,
          116,
          117,
          118,
          119,
          120,
          121,
          122,
          123,
          124,
          125,
          126,
          127,
          128,
          129,
          130,
          131,
          132,
          133,
          134,
          135,
          136,
          137,
          138,
          139,
          140,
          141,
          142,
          143,
          144,
          145,
          146,
          147,
          148,
          149,
          150,
          151,
          152,
          153,
          154,
          155,
          156,
          157,
          158,
          159,
          160,
          161,
          162,
          163,
          164,
          165,
          166,
          167,
          168,
          169,
          170,
          171,
          172,
          173,
          174,
          175,
          176,
          177,
          178,
          179,
          180,
          181,
          182,
          183,
          184,
          185,
          186,
          187,
          188,
          189,
          190,
          191,
          192,
          193,
          194,
          195,
          196,
          197,
          198,
          199,
          200,
          201,
          202,
          203,
          204,
          205,
          206,
          207,
          208,
          209,
          210,
          211,
          212,
          213,
          214,
          215,
          216,
          217,
          218,
          219,
          220,
          221,
          222,
          223,
          224,
          225,
          226,
          227,
          228,
          229,
          230,
          231,
          232,
          233,
          234,
          235,
          236,
          237,
          238,
          239,
          240,
          241,
          242,
          243,
          244,
          245,
          246,
          247,
          248,
          249,
          250,
          251,
          252,
          253,
          254,
          255,
          256,
          257,
          258,
          259,
          260,
          261,
          262,
          263,
          264,
          265,
          266,
          267,
          268,
          269,
          270,
          271,
          272,
          273,
          274,
          275,
          276,
          277,
          278,
          279,
          280,
          281,
          282,
          283,
          284,
          285,
          286,
          287,
          288,
          289,
          290,
          291,
          292,
          293,
          294,
          295,
          296,
          297,
          298,
          299,
          300,
          301,
          302,
          303,
          304,
          305,
          306,
          307,
          308,
          309,
          310,
          311,
          312,
          313,
          314,
          315,
          316,
          317,
          318,
          319,
          320,
          321,
          322,
          323,
          324,
          325,
          326,
          327,
          328,
          329,
          330,
          331,
          332,
          333,
          334,
          335,
          336,
          337,
          338,
          339,
          340,
          341,
          342,
          343,
          344,
          345,
          346,
          347,
          348,
          349,
          350
         ],
         "y": [
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346,
          0.346
         ]
        }
       ],
       "layout": {
        "height": 370,
        "margin": {
         "t": 100
        },
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "rgb(36,36,36)"
            },
            "error_y": {
             "color": "rgb(36,36,36)"
            },
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "baxis": {
             "endlinecolor": "rgb(36,36,36)",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "rgb(36,36,36)"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "line": {
              "color": "white",
              "width": 0.6
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 1,
              "tickcolor": "rgb(36,36,36)",
              "ticks": "outside"
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 1,
             "tickcolor": "rgb(36,36,36)",
             "ticks": "outside"
            },
            "colorscale": [
             [
              0,
              "#440154"
             ],
             [
              0.1111111111111111,
              "#482878"
             ],
             [
              0.2222222222222222,
              "#3e4989"
             ],
             [
              0.3333333333333333,
              "#31688e"
             ],
             [
              0.4444444444444444,
              "#26828e"
             ],
             [
              0.5555555555555556,
              "#1f9e89"
             ],
             [
              0.6666666666666666,
              "#35b779"
             ],
             [
              0.7777777777777778,
              "#6ece58"
             ],
             [
              0.8888888888888888,
              "#b5de2b"
             ],
             [
              1,
              "#fde725"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "rgb(237,237,237)"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "rgb(217,217,217)"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 1,
            "tickcolor": "rgb(36,36,36)",
            "ticks": "outside"
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "rgb(103,0,31)"
            ],
            [
             0.1,
             "rgb(178,24,43)"
            ],
            [
             0.2,
             "rgb(214,96,77)"
            ],
            [
             0.3,
             "rgb(244,165,130)"
            ],
            [
             0.4,
             "rgb(253,219,199)"
            ],
            [
             0.5,
             "rgb(247,247,247)"
            ],
            [
             0.6,
             "rgb(209,229,240)"
            ],
            [
             0.7,
             "rgb(146,197,222)"
            ],
            [
             0.8,
             "rgb(67,147,195)"
            ],
            [
             0.9,
             "rgb(33,102,172)"
            ],
            [
             1,
             "rgb(5,48,97)"
            ]
           ],
           "sequential": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#440154"
            ],
            [
             0.1111111111111111,
             "#482878"
            ],
            [
             0.2222222222222222,
             "#3e4989"
            ],
            [
             0.3333333333333333,
             "#31688e"
            ],
            [
             0.4444444444444444,
             "#26828e"
            ],
            [
             0.5555555555555556,
             "#1f9e89"
            ],
            [
             0.6666666666666666,
             "#35b779"
            ],
            [
             0.7777777777777778,
             "#6ece58"
            ],
            [
             0.8888888888888888,
             "#b5de2b"
            ],
            [
             1,
             "#fde725"
            ]
           ]
          },
          "colorway": [
           "#1F77B4",
           "#FF7F0E",
           "#2CA02C",
           "#D62728",
           "#9467BD",
           "#8C564B",
           "#E377C2",
           "#7F7F7F",
           "#BCBD22",
           "#17BECF"
          ],
          "font": {
           "color": "rgb(36,36,36)"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "white",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "margin": {
           "b": 0,
           "l": 20,
           "r": 20,
           "t": 40
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "white",
          "polar": {
           "angularaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "radialaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "yaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           },
           "zaxis": {
            "backgroundcolor": "white",
            "gridcolor": "rgb(232,232,232)",
            "gridwidth": 2,
            "linecolor": "rgb(36,36,36)",
            "showbackground": true,
            "showgrid": false,
            "showline": true,
            "ticks": "outside",
            "zeroline": false,
            "zerolinecolor": "rgb(36,36,36)"
           }
          },
          "shapedefaults": {
           "fillcolor": "black",
           "line": {
            "width": 0
           },
           "opacity": 0.3
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "baxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           },
           "bgcolor": "white",
           "caxis": {
            "gridcolor": "rgb(232,232,232)",
            "linecolor": "rgb(36,36,36)",
            "showgrid": false,
            "showline": true,
            "ticks": "outside"
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "rgb(232,232,232)",
           "linecolor": "rgb(36,36,36)",
           "showgrid": false,
           "showline": true,
           "ticks": "outside",
           "title": {
            "standoff": 15
           },
           "zeroline": false,
           "zerolinecolor": "rgb(36,36,36)"
          }
         }
        },
        "title": {
         "text": "$\\text{Loss as a Function of the Ensemble's size}$"
        },
        "width": 700,
        "xaxis": {
         "title": {
          "text": "$\\text{Ensemble's size}$"
         }
        },
        "yaxis": {
         "title": {
          "text": "$\\text{Loss}$"
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"f8a64457-13ba-473e-b31c-86e517ba9ec6\" class=\"plotly-graph-div\" style=\"height:370px; width:700px;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"f8a64457-13ba-473e-b31c-86e517ba9ec6\")) {                    Plotly.newPlot(                        \"f8a64457-13ba-473e-b31c-86e517ba9ec6\",                        [{\"mode\":\"lines\",\"name\":\"$\\\\text{Ensemble}$\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350],\"y\":[0.348,0.342,0.342,0.33,0.356,0.34,0.34,0.336,0.304,0.348,0.338,0.342,0.336,0.346,0.332,0.288,0.346,0.304,0.338,0.35,0.304,0.3,0.302,0.344,0.298,0.328,0.346,0.296,0.344,0.33,0.342,0.342,0.354,0.32,0.306,0.304,0.298,0.296,0.304,0.302,0.332,0.298,0.304,0.3,0.308,0.296,0.298,0.302,0.304,0.356,0.298,0.304,0.302,0.308,0.29,0.306,0.302,0.308,0.296,0.296,0.3,0.298,0.284,0.302,0.302,0.338,0.308,0.298,0.3,0.3,0.318,0.302,0.302,0.306,0.3,0.3,0.302,0.302,0.302,0.306,0.302,0.3,0.306,0.3,0.306,0.302,0.304,0.344,0.302,0.344,0.298,0.3,0.288,0.308,0.338,0.306,0.338,0.302,0.298,0.3,0.302,0.304,0.296,0.306,0.298,0.298,0.304,0.34,0.298,0.302,0.294,0.304,0.296,0.298,0.322,0.298,0.3,0.338,0.302,0.34,0.304,0.308,0.3,0.298,0.3,0.306,0.288,0.298,0.34,0.338,0.304,0.3,0.304,0.298,0.306,0.338,0.304,0.334,0.302,0.3,0.296,0.304,0.302,0.302,0.3,0.302,0.306,0.3,0.304,0.3,0.294,0.304,0.3,0.3,0.3,0.302,0.306,0.304,0.29,0.338,0.302,0.3,0.302,0.342,0.302,0.27,0.298,0.3,0.306,0.3,0.298,0.302,0.298,0.3,0.298,0.3,0.298,0.3,0.306,0.3,0.302,0.306,0.302,0.3,0.302,0.302,0.304,0.3,0.298,0.302,0.302,0.304,0.302,0.298,0.296,0.296,0.302,0.3,0.306,0.306,0.3,0.3,0.294,0.294,0.34,0.286,0.284,0.296,0.3,0.302,0.3,0.306,0.3,0.302,0.304,0.304,0.304,0.298,0.302,0.302,0.306,0.304,0.302,0.3,0.302,0.304,0.3,0.302,0.3,0.306,0.304,0.298,0.298,0.292,0.3,0.3,0.3,0.302,0.302,0.3,0.3,0.302,0.302,0.306,0.298,0.298,0.304,0.3,0.3,0.296,0.306,0.306,0.304,0.3,0.306,0.302,0.3,0.3,0.302,0.306,0.3,0.3,0.306,0.306,0.298,0.3,0.296,0.302,0.298,0.302,0.306,0.298,0.298,0.304,0.306,0.292,0.302,0.306,0.304,0.298,0.306,0.298,0.298,0.302,0.3,0.302,0.304,0.298,0.304,0.306,0.296,0.3,0.296,0.3,0.302,0.304,0.286,0.302,0.306,0.302,0.302,0.302,0.3,0.302,0.304,0.302,0.302,0.3,0.3,0.306,0.302,0.304,0.302,0.298,0.304,0.306,0.302,0.306,0.306,0.304,0.3,0.302,0.306,0.3,0.302,0.304,0.3,0.302,0.304,0.306,0.304,0.296,0.304,0.306,0.304,0.296,0.306,0.302,0.306,0.298,0.302,0.3,0.3,0.302,0.298,0.306,0.304,0.3,0.304,0.298],\"type\":\"scatter\"},{\"mode\":\"lines\",\"name\":\"$\\\\text{Single Tree}$\",\"x\":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350],\"y\":[0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346,0.346],\"type\":\"scatter\"}],                        {\"height\":370,\"margin\":{\"t\":100},\"title\":{\"text\":\"$\\\\text{Loss as a Function of the Ensemble's size}$\"},\"width\":700,\"xaxis\":{\"title\":{\"text\":\"$\\\\text{Ensemble's size}$\"}},\"yaxis\":{\"title\":{\"text\":\"$\\\\text{Loss}$\"}},\"template\":{\"data\":{\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"bar\":[{\"error_x\":{\"color\":\"rgb(36,36,36)\"},\"error_y\":{\"color\":\"rgb(36,36,36)\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"baxis\":{\"endlinecolor\":\"rgb(36,36,36)\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"rgb(36,36,36)\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"choropleth\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"contourcarpet\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"contour\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmapgl\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"heatmap\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2dcontour\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"histogram2d\"}],\"histogram\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.6}},\"type\":\"histogram\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scattermapbox\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolargl\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterpolar\"}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"},\"colorscale\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"rgb(237,237,237)\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"rgb(217,217,217)\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":1,\"tickcolor\":\"rgb(36,36,36)\",\"ticks\":\"outside\"}},\"colorscale\":{\"diverging\":[[0.0,\"rgb(103,0,31)\"],[0.1,\"rgb(178,24,43)\"],[0.2,\"rgb(214,96,77)\"],[0.3,\"rgb(244,165,130)\"],[0.4,\"rgb(253,219,199)\"],[0.5,\"rgb(247,247,247)\"],[0.6,\"rgb(209,229,240)\"],[0.7,\"rgb(146,197,222)\"],[0.8,\"rgb(67,147,195)\"],[0.9,\"rgb(33,102,172)\"],[1.0,\"rgb(5,48,97)\"]],\"sequential\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]],\"sequentialminus\":[[0.0,\"#440154\"],[0.1111111111111111,\"#482878\"],[0.2222222222222222,\"#3e4989\"],[0.3333333333333333,\"#31688e\"],[0.4444444444444444,\"#26828e\"],[0.5555555555555556,\"#1f9e89\"],[0.6666666666666666,\"#35b779\"],[0.7777777777777778,\"#6ece58\"],[0.8888888888888888,\"#b5de2b\"],[1.0,\"#fde725\"]]},\"colorway\":[\"#1F77B4\",\"#FF7F0E\",\"#2CA02C\",\"#D62728\",\"#9467BD\",\"#8C564B\",\"#E377C2\",\"#7F7F7F\",\"#BCBD22\",\"#17BECF\"],\"font\":{\"color\":\"rgb(36,36,36)\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"white\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"rgb(232,232,232)\",\"gridwidth\":2,\"linecolor\":\"rgb(36,36,36)\",\"showbackground\":true,\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"}},\"shapedefaults\":{\"fillcolor\":\"black\",\"line\":{\"width\":0},\"opacity\":0.3},\"ternary\":{\"aaxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"baxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"rgb(232,232,232)\",\"linecolor\":\"rgb(36,36,36)\",\"showgrid\":false,\"showline\":true,\"ticks\":\"outside\",\"title\":{\"standoff\":15},\"zeroline\":false,\"zerolinecolor\":\"rgb(36,36,36)\"},\"margin\":{\"b\":0,\"l\":20,\"r\":20,\"t\":40}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('f8a64457-13ba-473e-b31c-86e517ba9ec6');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate 2D data to of 2 classes\n",
    "d, n_train, n_test = 5, 2000, 500\n",
    "X, y = create_data_bagging_utils(d=d, n_samples = n_train + n_test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=n_test, random_state=42)\n",
    "depth = 2  # The depth of the single decision tree and of each tree in the ensemble\n",
    "\n",
    "tree = DecisionTreeClassifier(max_depth=depth).fit(X_train, y_train)\n",
    "tree_loss = np.sum(tree.predict(X_test) != y_test) / len(y_test)\n",
    "\n",
    "ensemble_losses = []\n",
    "nums = list(range(1, 351))\n",
    "for num_trees in nums:\n",
    "    ensemble = TreeEnsemble(num_trees, depth).fit(X_train, y_train)\n",
    "    ensemble_losses.append(np.sum(ensemble.predict(X_test) != y_test) / len(y_test))\n",
    "\n",
    "go.Figure([go.Scatter(x=nums, y=ensemble_losses, mode='lines', name=r\"$\\text{Ensemble}$\"), \n",
    "                 go.Scatter(x=nums, y=[tree_loss for i in nums], mode='lines', name=r\"$\\text{Single Tree}$\")],\n",
    "                layout=go.Layout(title=rf\"$\\text{{Loss as a Function of the Ensemble's size}}$\", margin=dict(t=100),\n",
    "                                 xaxis_title=r\"$\\text{Ensemble's size}$\", yaxis_title=r\"$\\text{Loss}$\",\n",
    "                                 width=700, height=370))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "class StagedAdaBoostClassifier(AdaBoostClassifier):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(*kwargs)\n",
    "        self.sample_weights = []\n",
    "\n",
    "    def _boost(self, iboost, X, y, sample_weight, random_state):\n",
    "        self.sample_weights.append(sample_weight.copy())\n",
    "#         self.res_list.append(super()._boost(iboost, X, y, sample_weight, random_state))\n",
    "#         return self.res_list[-1]\n",
    "        return super()._boost(iboost, X, y, sample_weight, random_state)\n",
    "\n",
    "    def _iteration_callback(self, iboost, X, y, sample_weight, \n",
    "                            estimator_weight = None, estimator_error = None):\n",
    "        self.sample_weights.append(sample_weight.copy())\n",
    "        \n",
    "        \n",
    "from sklearn.datasets import make_gaussian_quantiles\n",
    "\n",
    "# Construct dataset of two sets of Gaussian quantiles\n",
    "X1, y1 = make_gaussian_quantiles(cov=2., n_samples=50, n_features=2, n_classes=2, random_state=1)\n",
    "X2, y2 = make_gaussian_quantiles(mean=(3, 3), cov=1.5, n_samples=50, n_features=2, n_classes=2, random_state=1)\n",
    "X, y = np.concatenate((X1, X2)), np.concatenate((y1, - y2 + 1))\n",
    "\n",
    "\n",
    "# Form grid of points to use for plotting decision boundaries \n",
    "lims = np.array([X.min(axis=0), X.max(axis=0)]).T + np.array([-.2, .2])\n",
    "xx, yy = list(map(np.ravel, np.meshgrid(np.arange(*lims[0], .2), np.arange(*lims[1], .2))))\n",
    "\n",
    "\n",
    "# Fit AdaBoost classifier over training set\n",
    "model = StagedAdaBoostClassifier().fit(X, y)\n",
    "# Retrieve model train error at each iteration of fitting\n",
    "staged_scores = list(model.staged_score(X, y))\n",
    "# Predict labels of grid points at each iteration of fitting\n",
    "staged_predictions = np.array(list(model.staged_predict(np.vstack([xx, yy]).T)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create animation frames\n",
    "frames = []\n",
    "for i in range(len(staged_predictions)):\n",
    "    frames.append(go.Frame(\n",
    "        data=[\n",
    "            # Scatter of sample weights\n",
    "            go.Scatter(x=X[:,0], y= X[:,1], mode='markers', showlegend=False, marker=dict(color=y, colorscale=class_colors(2),\n",
    "                       size=np.maximum(230*model.sample_weights[i]+1, np.ones(len(model.sample_weights[i]))*5)),\n",
    "                       xaxis=\"x\", yaxis=\"y\"), \n",
    "            \n",
    "            # Staged decision surface \n",
    "            go.Scatter(x=xx,  y=yy, marker=dict(symbol = \"square\", colorscale=custom, color=staged_predictions[i,:]), \n",
    "                       mode='markers', opacity = 0.4, showlegend=False, xaxis=\"x2\", yaxis=\"y2\"),\n",
    "            \n",
    "            # Scatter of train samples with true class\n",
    "            go.Scatter(x=X[:,0],  y=X[:,1], mode='markers', showlegend=False, xaxis=\"x2\", yaxis=\"y2\",\n",
    "                       marker=dict(color=y, colorscale=class_colors(2), symbol=class_symbols[y])),\n",
    "            \n",
    "            # Scatter of staged score\n",
    "            go.Scatter(x=list(range(i)), y=staged_scores[:i], mode='lines+markers', showlegend=False, marker_color=\"black\",\n",
    "                       xaxis=\"x3\", yaxis=\"y3\")\n",
    "        ],\n",
    "        layout = go.Layout(title = rf\"$\\text{{AdaBoost Training - Iteration }}{i+1}/{len(staged_predictions)}$)\"),\n",
    "        traces=[0, 1, 2, 3]))    \n",
    "\n",
    "    \n",
    "fig = make_subplots(rows=2, cols=2, row_heights=[350, 200],\n",
    "                    subplot_titles=(r\"$\\text{Sample Weights}$\", r\"$\\text{Decisions Boundaries}$\", \n",
    "                                    r\"$\\text{Ensemble Train Accuracy}$\"),\n",
    "                    specs=[[{}, {}], [{\"colspan\": 2}, None]])\\\n",
    "    .add_traces(data=frames[0].data, rows=[1,1,1,2], cols=[1,2,2,1])\\\n",
    "    .update(frames = frames)\\\n",
    "    .update_layout(title=frames[0].layout.title,\n",
    "                   updatemenus = [dict(type=\"buttons\", buttons=[AnimationButtons.play(), AnimationButtons.pause()])], \n",
    "                   width=600, height=550, margin=dict(t=100))\\\n",
    "    .update_yaxes(range=[min(staged_scores)-.1, 1.1], autorange=False, row=2, col=1)\\\n",
    "    .update_xaxes(range=[0, len(frames)], autorange=False, row=2, col=1)\n",
    "\n",
    "animation_to_gif(fig, \"../figures/adaboost.gif\", 1000, width=600, height=550)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
